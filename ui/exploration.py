# -*- coding: utf-8 -*-
'''
Created on Mon Oct 25 11:35:11 2021

@author: shangfr
'''
import pandas as pd
import streamlit as st
from model.preprocessing import transformer


def reset_step():
    '''reset_step.
    '''
    st.session_state['ml_step'] = 1


def show_data(origin):
    '''EDA.
    '''
    data = origin['data']
    dtype_table = origin['dtype_table']

    st.info('1. æ•°æ®æè¿°(EDA)', icon='ğŸ‘‡')
    tab1, tab2 = st.tabs(['å˜é‡æè¿°', 'æŸ¥çœ‹æ•°æ®'])

    with tab1:
        (row_n, col_n) = data.shape

        col1, col2 = st.columns([2, 8])
        col1.metric(label='Data Shape', value=str(col_n)+'åˆ—',
                          delta=str(row_n)+'è¡Œ', delta_color='inverse')
        edited_df = col2.experimental_data_editor(dtype_table)

    with tab2:
        st.dataframe(data.head(200))

    filter0 = edited_df['effective'] == True

    return edited_df[filter0]


@st.cache_data
def convert_df(X, feature_names):
    # IMPORTANT: Cache the conversion to prevent computation on every rerun
    df = pd.DataFrame(X, columns=feature_names)
    return df.to_csv(index=False).encode('utf-8')


def data_exploration(cache_data):
    '''ML type select.
    '''
    origin = cache_data['origin']
    data = origin['data']

    dtype_table = show_data(origin)

    st.info('2. æœºå™¨å­¦ä¹ (Machine Learning)', icon='ğŸ‘‡')

    variable = dtype_table['variable']

    filter1 = dtype_table['dtypes'] != 'category'
    num_cols = variable[filter1]

    machine_learning = cache_data['machine_learning']
    ml_parm = machine_learning['parm']

    m_type_lst = ['åˆ†ç±»', 'å›å½’', 'èšç±»']
    col1, col2, col3 = st.columns(3)
    model_type = col1.selectbox(
        'ç±»å‹', m_type_lst, key='m_type', on_change=reset_step)
    ml_parm['model_type'] = model_type
    if model_type == m_type_lst[0]:
        cls_n = col2.number_input(
            'ç±»åˆ«æ•°', 2, 3, key='cls_n', help='äºŒåˆ†ç±»æˆ–å¤šåˆ†ç±»')
        ml_parm['cls_n'] = cls_n
        filter2 = dtype_table['var_count'] == cls_n

        tar_var_cls = variable[filter2].tolist()

        if len(tar_var_cls) > 0:
            target = col3.selectbox(
                'ç›®æ ‡å˜é‡', tar_var_cls, key='target', help='äºŒåˆ†ç±»æˆ–å¤šåˆ†ç±»ï¼Œä¸”ç±»åˆ«æ•°<5')

        else:
            col1.error(f'{cls_n}åˆ†ç±»æ¨¡å‹ç›®æ ‡å˜é‡ä¸å­˜åœ¨ï¼', icon='ğŸš¨')
            st.stop()

        t_list = data[target].unique().tolist()

        positive = col3.selectbox(
            'True Positive', t_list, key='positive', help='Value of positive class')
        ml_parm['positive'] = positive
        p_per_t = (data[target] == positive).value_counts(normalize=True)
        if p_per_t[True] < 0.25:
            st.error(
                f'{cls_n}åˆ†ç±»æ¨¡å‹ç›®æ ‡å˜é‡æ ·æœ¬ä¸å‡è¡¡ï¼Œ{positive}å æ¯”{p_per_t[True]}å°äº0.25ã€‚', icon='ğŸš¨')
            st.stop()

    elif model_type == m_type_lst[1]:
        if len(num_cols) > 0:
            filter3 = dtype_table['var_count'] > 10

            tar_var_regr = variable[filter3].tolist()

            target = col3.selectbox(
                'ç›®æ ‡å˜é‡', tar_var_regr, key='target_n', help='åªèƒ½æ˜¯è¿ç»­å‹æ•°å€¼å˜é‡')

        else:
            col3.error('å›å½’æ¨¡å‹ç›®æ ‡å˜é‡ä¸å­˜åœ¨ï¼', icon='ğŸš¨')
            st.stop()
        #data[target] = pd.to_numeric(data[target], errors='coerce')

    elif model_type == m_type_lst[2]:
        target = ''

    variable = variable[variable != target].tolist()
    num_cols = num_cols[num_cols != target].tolist()

    dtypes = ['æ•°å€¼å‹', 'åˆ†ç±»å‹', 'æ—¶é—´å‹', 'æè¿°å‹']
    variable = list(variable)
    features_num_cols = st.multiselect(
        f'ç‰¹å¾å˜é‡({dtypes[0]})', list(num_cols), list(num_cols), disabled=st.session_state.disabled)
    variable = [c for c in variable if c not in features_num_cols]

    features_cat_cols = st.multiselect(
        f'ç‰¹å¾å˜é‡({dtypes[1]})', list(variable), list(variable), disabled=st.session_state.disabled)
    variable = [c for c in variable if c not in features_cat_cols]

    features = {'num_cols': features_num_cols, 'cat_cols': features_cat_cols}

    max_n = len(features_num_cols) + len(features_cat_cols)
    if max_n < 2:
        st.error('Number of features cannot be less than 2.', icon='ğŸš¨')
        st.stop()

    ml_parm['target'] = target
    ml_parm['features'] = features
    ml_parm['feature_names'] = features['num_cols']+features['cat_cols']
    ml_parm['max_n'] = max_n

    submitted = st.button('ğŸ”§ é¢„å¤„ç†')
    if submitted:

        datasets, preprocessor = transformer(data, ml_parm)

        machine_learning['datasets'] = datasets
        machine_learning['model_pipe']['preprocessor'] = preprocessor
        st.session_state['ml_step'] = 2

    if st.session_state['ml_step'] == 1:
        st.warning('è¯·å…ˆç‚¹å‡»ğŸ”§è¿›è¡Œæ•°æ®é¢„å¤„ç†', icon='âš ï¸')
        st.stop()

    col0, col1 = st.sidebar.columns([1, 5])
    col1.success('å·²å®Œæˆæ•°æ®é¢„å¤„ç†')

    X = machine_learning['datasets']['X']
    feature_names = machine_learning['parm']['feature_names']
    csv_data = convert_df(X, feature_names)
    col0.download_button(
        label='ğŸ“',
        data=csv_data,
        file_name='preprocessing_df.csv',
        mime='text/csv',
        help='download the preprocessing dataframe.'
    )
